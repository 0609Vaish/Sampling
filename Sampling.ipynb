{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment-Sampling"
      ],
      "metadata": {
        "id": "4kMhm7yzbhSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler"
      ],
      "metadata": {
        "id": "XK51ADlYQzsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Load the dataset"
      ],
      "metadata": {
        "id": "pZVQedSDboon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('Creditcard_data.csv')\n",
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']"
      ],
      "metadata": {
        "id": "7nq2RuKWWKEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Balance the dataset"
      ],
      "metadata": {
        "id": "XoPMbA6Wb1kQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oversampler = RandomOverSampler(random_state=42)\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "X_over, y_over = oversampler.fit_resample(X, y)\n",
        "X_under, y_under = undersampler.fit_resample(X, y)\n"
      ],
      "metadata": {
        "id": "WyUprDX6Xlrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Sample size detection formula"
      ],
      "metadata": {
        "id": "jqs2jU91cB6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_sample_size(total, margin_of_error=0.05, confidence=0.95):\n",
        "    z = 1.96  # 95% confidence level\n",
        "    p = 0.5  # Maximum variability\n",
        "    n = (z**2 * p * (1 - p)) / (margin_of_error**2)\n",
        "    return min(int(n), total)\n",
        "\n",
        "sample_size = calculate_sample_size(len(X))\n"
      ],
      "metadata": {
        "id": "uG0I5mM0Xw6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Sampling techniques"
      ],
      "metadata": {
        "id": "SEIFqF5FcEHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Simple Random Sampling\n",
        "X_simple, _, y_simple, _ = train_test_split(X_over, y_over, train_size=sample_size, random_state=1)\n"
      ],
      "metadata": {
        "id": "HQEsbgpGX87I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stratified Sampling\n",
        "X_stratified, _, y_stratified, _ = train_test_split(X, y, train_size=sample_size, stratify=y, random_state=3)\n"
      ],
      "metadata": {
        "id": "b2TRJQy5YkOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cluster Sampling\n",
        "def cluster_sample(X, y, clusters, size):\n",
        "    groups = np.array_split(X.index, clusters)\n",
        "    selected = np.concatenate(groups[:size // (len(X) // clusters)])\n",
        "    return X.loc[selected], y.loc[selected]\n",
        "\n",
        "X_cluster, y_cluster = cluster_sample(X_over, y_over, 10, sample_size)"
      ],
      "metadata": {
        "id": "whKq-EwRYp3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bootstrap Sampling\n",
        "def bootstrap_sample(X, y, size):\n",
        "    indices = np.random.choice(len(X), size=size, replace=True)\n",
        "    return X.iloc[indices], y.iloc[indices]\n",
        "\n",
        "X_bootstrap, y_bootstrap = bootstrap_sample(X_over, y_over, sample_size)"
      ],
      "metadata": {
        "id": "xEiJQxBPY1Uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Train models"
      ],
      "metadata": {
        "id": "Esy8wre1cNsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"SVM\": SVC(),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "samples = {\n",
        "    \"Simple Random\": (X_simple, y_simple),\n",
        "\n",
        "    \"Stratified\": (X_stratified, y_stratified),\n",
        "    \"Cluster\": (X_cluster, y_cluster),\n",
        "    \"Bootstrap\": (X_bootstrap, y_bootstrap)\n",
        "}\n",
        "\n",
        "results = []\n",
        "for model_name, model in models.items():\n",
        "    for sample_name, (X_samp, y_samp) in samples.items():\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_samp, y_samp, test_size=0.3, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "        accuracy = accuracy_score(y_test, model.predict(X_test))\n",
        "        results.append({\"Model\": model_name, \"Sample\": sample_name, \"Accuracy\": accuracy})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPxTdezDY8Cu",
        "outputId": "a742d6f4-295d-4f9d-a11e-599393deeff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Results"
      ],
      "metadata": {
        "id": "rfWxAU36cUQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Results\n",
        "results_df = pd.DataFrame(results)\n",
        "best_results = results_df.loc[results_df.groupby(\"Model\")['Accuracy'].idxmax()]\n",
        "\n",
        "print(\"All Results:\")\n",
        "print(results_df)\n",
        "print(\"\\nBest Results:\")\n",
        "print(best_results)\n",
        "\n",
        "# Save results to CSV\n",
        "results_df.to_csv('all_results.csv', index=False)\n",
        "best_results.to_csv('best_results.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_zBn28fZ3MA",
        "outputId": "6e8f4b65-b3c1-47b6-be58-3ec9f1d0257f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Results:\n",
            "                  Model         Sample  Accuracy\n",
            "0         Random Forest  Simple Random  0.991379\n",
            "1         Random Forest     Stratified  0.991379\n",
            "2         Random Forest        Cluster  0.978261\n",
            "3         Random Forest      Bootstrap  1.000000\n",
            "4   Logistic Regression  Simple Random  0.853448\n",
            "5   Logistic Regression     Stratified  0.991379\n",
            "6   Logistic Regression        Cluster  0.956522\n",
            "7   Logistic Regression      Bootstrap  0.913793\n",
            "8                   SVM  Simple Random  0.750000\n",
            "9                   SVM     Stratified  0.991379\n",
            "10                  SVM        Cluster  0.978261\n",
            "11                  SVM      Bootstrap  0.724138\n",
            "12                  KNN  Simple Random  0.956897\n",
            "13                  KNN     Stratified  0.991379\n",
            "14                  KNN        Cluster  0.978261\n",
            "15                  KNN      Bootstrap  0.939655\n",
            "16        Decision Tree  Simple Random  0.982759\n",
            "17        Decision Tree     Stratified  0.982759\n",
            "18        Decision Tree        Cluster  0.978261\n",
            "19        Decision Tree      Bootstrap  0.974138\n",
            "\n",
            "Best Results:\n",
            "                  Model         Sample  Accuracy\n",
            "16        Decision Tree  Simple Random  0.982759\n",
            "13                  KNN     Stratified  0.991379\n",
            "5   Logistic Regression     Stratified  0.991379\n",
            "3         Random Forest      Bootstrap  1.000000\n",
            "9                   SVM     Stratified  0.991379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = 'sampling.pkl'  # File name for the pickled model\n",
        "with open(filename, 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "\n",
        "print(f\"Model saved as {filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Suo9h9HQaEKf",
        "outputId": "5eda1b72-9ee9-47e9-a980-a4ebab35b4b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as sampling.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "JLHfAMM5aOxO",
        "outputId": "1ee2d265-9718-4744-9031-131f7c81aedf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_23f04036-a75b-4183-8c83-4fa64b392c96\", \"sampling.pkl\", 2763)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pickled model\n",
        "with open(filename, 'rb') as file:\n",
        "    loaded_model = pickle.load(file)\n",
        "\n",
        "# Use the loaded model for predictions\n",
        "predictions = loaded_model.predict(X_test)\n",
        "print(\"Predictions:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJR4Ska1akXO",
        "outputId": "829b730a-bb23-4630-ce01-1101cca51ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [1 1 0 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0 1 0\n",
            " 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0\n",
            " 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1\n",
            " 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Save the pickle file to Google Drive\n",
        "pickle_path = '/content/drive/My Drive/sampling.pkl'\n",
        "with open(pickle_path, 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "\n",
        "print(f\"Model saved to {pickle_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHnvhHOIapWP",
        "outputId": "2be8517a-ace0-4dba-be4b-e0eee3ad5dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model saved to /content/drive/My Drive/sampling.pkl\n"
          ]
        }
      ]
    }
  ]
}